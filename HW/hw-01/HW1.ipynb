{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intructions**\n",
    "\n",
    "In this problem set, we'll be learning the basics of Numpy, Scipy, and Matplotlib. This coding assignment is split up into tree parts: a short \"warm-up\" exercises, medium coding exercises, and an application to economics.\n",
    "\n",
    "A blank code or markup cell will be left after each exercise for you to fill in with your solution.\n",
    "\n",
    "I've completed the first few exercises for you to show you how you should format your HW submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell below to add section numbering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "body {\n",
       "  counter-reset: section subsection;\n",
       "}\n",
       "\n",
       "h1 {\n",
       "  counter-reset: subsection;\n",
       "}\n",
       "\n",
       "h1:before {\n",
       "    counter-increment: section;\n",
       "    content: \"\" counter(section) \". \";\n",
       "}\n",
       "\n",
       "h2:before {\n",
       "    counter-increment: subsection;\n",
       "    content: counter(section) \".\" counter(subsection) \" \";\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%HTML\n",
    "<style>\n",
    "body {\n",
    "  counter-reset: section subsection;\n",
    "}\n",
    "\n",
    "h1 {\n",
    "  counter-reset: subsection;\n",
    "}\n",
    "\n",
    "h1:before {\n",
    "    counter-increment: section;\n",
    "    content: \"\" counter(section) \". \";\n",
    "}\n",
    "\n",
    "h2:before {\n",
    "    counter-increment: subsection;\n",
    "    content: counter(section) \".\" counter(subsection) \" \";\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warmup\n",
    "\n",
    "## Import Necessary Modules\n",
    "\n",
    "You should always start you file with all of the `import` statements that you will be using for the file. This makes it easier to quickly check what modules each file depends on---all you have to do is look at the top of the file. \n",
    "\n",
    "For this problem, import numpy, scipy, and the pyplot submodule from matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completed for you\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scipy.integrate\n",
    "import scipy.stats\n",
    "from scipy import misc\n",
    "from scipy.optimize import minimize\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use built-in Numpy functions to do the following tasks\n",
    "\n",
    "1. Create a vector (numpy array) of size 10 that contains all zeros and print it. (Use np.zeros.)\n",
    "2. Use `arange` to create a vector of values from 5 to 24. Print it.\n",
    "3. Use `arange` and Python \"slicing\" to create a vector of values from 24, to 5. Print it.\n",
    "4. Use `arange` and Python \"slicing\" to create a vector consisting of all the even integers in the half-open interval $[0,30)$.\n",
    "5. Use `arange` and `reshape` to create a 3x3 numpy array containing the numbers 0 to 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completed for you\n",
    "\n",
    "# 1\n",
    "print(\"1.\")\n",
    "Z = np.zeros(10)\n",
    "print(Z)\n",
    "\n",
    "# 2\n",
    "print(\"2.\")\n",
    "print(np.arange(5,25))\n",
    "\n",
    "# 3\n",
    "print(\"3.\")\n",
    "z = np.arange(5, 25)\n",
    "print(z[::-1])\n",
    "\n",
    "# 4\n",
    "print(\"4.\")\n",
    "z = np.arange(0,30)\n",
    "print(z[::2])\n",
    "\n",
    "# 5\n",
    "print(\"5.\")\n",
    "print(np.arange(0,9).reshape((3,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy functions continued... (2 points each)\n",
    "\n",
    "1. Use `eye` to create a 5x5 identity matrix. Print it.\n",
    "2. Use `random.random` to generate a 3x3x3 array of numbers randomly generated from a uniform distribution over the support interval $[0,1)$. Print it.\n",
    "3. Create a 10x10 array with similarly generated random values. Find and print the minimum and maximum values appearing in the matrix using `min` and `max`.\n",
    "4. Create a random vector of size 30. Find and print the mean value.\n",
    "5. Use `zeros` and/or `ones` and slicing to create a 10x10 array with 1's on the border and 0's inside."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "print(\"1.\")\n",
    "print(\"2.\")\n",
    "print(\"3.\")\n",
    "print(\"4.\")\n",
    "print(\"5.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration with Scipy (2 points)\n",
    "\n",
    " - (1) The PDF of a Normal distibution is \n",
    " $$\n",
    "f(x; \\mu, \\sigma) =  \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left\\{- \\frac{(x - \\mu)^2}{2 \\sigma^2}\\right\\}\n",
    " $$\n",
    " \n",
    " Let $\\mu = 1$ and $\\sigma = 2$. Use Scipy to numerical integrate this function. Specifically, calculate\n",
    " $$\n",
    " \\int_{-2}^{2} f(x; \\mu, \\sigma) \\mathrm d x\n",
    " $$\n",
    " \n",
    " Verify your result using the built-in function for the CDF of a normal distribution: `scipy.stats.norm.cdf(x, loc=mu, scale=sigma)`. To calculate the proper area as the integral above, you will need to compute\n",
    " $$\n",
    " F(2) - F(-2),\n",
    " $$\n",
    " where $F$ is the CDF of the normal with mean 1 and standard deviation 2.\n",
    " \n",
    " (Hint: You will need to import `scipy.integrate` and `scipy.stats` to access the functions that you need.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medium Exercises\n",
    "\n",
    "## Array Indexing with an Image (4 points)\n",
    "\n",
    "Run the code in the cell below to access a matrix called `face`. Print the matrix to get an idea of what it looks like. What is its dimensions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import misc\n",
    "face = misc.face(gray=True).astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the following code to plot the elements of the matrix as an image: `plt.imshow(face, cmap=plt.cm.gray)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, apply the function `np.sin(x/25)` to the face matrix and then plot it again. This doesn't do anything very deep, it just messes with the shades of gray in a nonlinear way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine a circle with a center at the matrix indices (300, 620) and a radius of 250. In the x-y plane, this would be 620, 300. Write a snippet of code that, for each pixel, calculates the distance of that pixel from the center of this circle. If the distance is greater than the radius of the circle, set the value of the pixel (the element of the matrix) equal to zero. Plot the result, again using `plt.ishow` with a gray colormap.\n",
    "\n",
    "Be sure to create a new copy of the `face` matrix, `face2`. Create a proper copy using the `copy` method of the `np.array` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finish the following code.\n",
    "\n",
    "face2 = face.copy()\n",
    "cx, cy = 620, 300\n",
    "radius = 250\n",
    "for i in range(face.shape[0]):\n",
    "    for j in range(face.shape[1]):        \n",
    "        # TODO: Your code here\n",
    "        pass\n",
    "        \n",
    "plt.imshow(face2, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressing an Image with Linear Algebra (2 points for each part)\n",
    "\n",
    "Here we'll play with the Singular Value Decomposition (SVD) function in Numpy's `linalg` submodule. You can think of the SVD as a generalization of the eigenvalue decomposition for non-square matrices.\n",
    "\n",
    "Here we will be using the same `face` matrix as above.\n",
    "\n",
    " - (1) To begin, calculate the SVD using the code. (For this part, you can just copy and paste this code.)\n",
    " \n",
    "     `u, s, v = np.linalg.svd(face, full_matrices=False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (2) Calculate the shape of `u`, `s`, and `v`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (3) Construct a matrix by matrix multiplying `u`, `s`, and `v`. Note that `s` doesn't conform as it stands. Mathematically, we want to compute \n",
    "$$\n",
    "U \\cdot \\text{diag}(S) \\cdot V.\n",
    "$$\n",
    "Thus, we need $\\text{diag}(S)$ to be a 768 x 768 matrix with the values of `s` on the diagonal. These are the singular values---analogous to the eigenvalues---of the `face` matrix. Use `np.diag` to do this. Use `@` to perform the matrix multplication. Call this new matrix `faceUSV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (4) Use the function `np.allclose` to test if all of the elements of the matrices `faceUSV` and `face` are numerically close. Does this verify that our reconstruction was successful? Why are we using `np.allclose` instead of, say, `faceUSV == face` to test if the matrices are the same?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (5) Now, construct a function called `compress` that takes in a number `n` and returns a matrix constructed as follows:\n",
    " \n",
    "$$\n",
    "U_n \\cdot \\text{diag}(S_n) \\cdot V_n\n",
    "$$\n",
    "where $U_n$ is only the first `n` columns of the matrix `u`, $\\text{diag}(S_n)$ is the first `n` singular values put on the diagonals of a matrix of zeros (hint: `np.diag(s[0:n])`), and $V_n$ is the first `n` rows of the matrix `v`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (6) Use your newly created `compress` function to create the a matrix called `face_compressed` for various values of `n`. Plot the matrix using `plt.imshow(face_compressed, cmap=plt.cm.gray)`. Do this for `n in [500, 300, 100, 50, 10]`. What do you see happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (7). Again use the `size` method to calculate the number of \"pixels\" (elements in the array) that are in the original `face` matrix. Now, suppose we use the SVD to store this image. Write a function called `storage_size` that computes that number of elements in $U_r$, the number of elements in $V_r$, adds them together, and then adds $n$ for the number of singular values of the $S_r$ vector used. That is\n",
    " \n",
    " $$\n",
    " storageSize = numberOfElements(U_n) + numberOfElements(V_n) + numberOfElements(S_n)\n",
    " $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (8) Compute the storage size for each of the values of `n` that we tested above. Compared to the original size, `face.size`,\n",
    " how much space are we saving (in percentages) when we use `n=100` (which looks almost lossless)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Essentially, we are reconstructing the matrix (and image) using the first `n` singular values. Equivalently, we could say that we are using Principal Component Analysis and reconstructing the image using the first `n` principal components. If this were a square matrix, we could say that we are using the first `n` eigenvalues and eigenvectors.\n",
    "\n",
    "We will later see that this same technique can be used to analyze complex data. Imagine, for example, applying this procedure to a matrix of data or to the variance-covariance matrix of a set of variables. We will later see that, in the same way that we are compressing and summarizing a complex image, we can summarize the joint distribution of a set of variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a Curve to Data (2 points for each part)\n",
    "\n",
    "In this exercise, you will fit a nonlinear curve to data by minimizing the sum of squares. Below, I have given data and a function to plot the data and a curve over the data. The curve is the following function:\n",
    "$$\n",
    "y(t) = x_0 \\exp(-x_2 t) + x_1 \\exp(-x_3 t).\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "data = np.array(\n",
    "  [[0.0000, 5.8955], \n",
    "   [0.1000, 3.5639],\n",
    "   [0.2000, 2.5173],\n",
    "   [0.3000, 1.9790],\n",
    "   [0.4000, 1.8990],\n",
    "   [0.5000, 1.3938],\n",
    "   [0.6000, 1.1359],\n",
    "   [0.7000, 1.0096],\n",
    "   [0.8000, 1.0343],\n",
    "   [0.9000, 0.8435],\n",
    "   [1.0000, 0.6856],\n",
    "   [1.1000, 0.6100],\n",
    "   [1.2000, 0.5392],\n",
    "   [1.3000, 0.3946],\n",
    "   [1.4000, 0.3903],\n",
    "   [1.5000, 0.5474],\n",
    "   [1.6000, 0.3459],\n",
    "   [1.7000, 0.1370],\n",
    "   [1.8000, 0.2211],\n",
    "   [1.9000, 0.1704],\n",
    "   [2.0000, 0.2636]])\n",
    "\n",
    "def plot_against_data(x):\n",
    "    tgrid = data[:,0]\n",
    "    ydata = data[:,1]\n",
    "    yfunc = lambda t: x[0] * np.exp(-x[2]* t) + x[1] * np.exp(-x[3] * t)\n",
    "    y = yfunc(tgrid)\n",
    "    plt.plot(tgrid, ydata, '.')\n",
    "    plt.plot(tgrid, y)\n",
    "    \n",
    "x_initial = np.array([1, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (1): Use the given plotting function to plot the data and the curve for the given initial guess of the parameters, `x_initial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (2) Write a function called `sum_squares` that takes in a vector of model paraters (e.g., `x_initial`) and returns the sum of squares that results from the difference of the data and the curve defined by `x_initial`. What is the sum of squares that results from the given `x_initial`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (3) Use `scipy.optimize.minimize` to minimize the sum of squares, using the function that you wrote previously. Save the optimal parameters to the variable `xstar`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (4) Use the `plot_against_data` function that was given to plot the optimal curve, defined by `xstar`, against the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application: Mean-Variance Efficient Portfolios (4 points for each part)\n",
    "\n",
    "In this application, we replicate the Markowitz model of portfolio optimization. This model is a model of investor behavior. It models an investor you prefers a portfolio that has higher expected returns and lower variance, *ceteris paribus*. The result of this assumption is that investors (1) choose diversified portfolios and (2) that there exist on a \"mean-variance efficient frontier\" along which investors choose their portfolios. That is, there are some portfolios that consist of some combinations of assets that are strictly dominated by other combinations of assets. This model  formalizes the notion that an investor should not \"put all of his/her eggs in one basket\" as well as  the tradeoff between risk and return.\n",
    "\n",
    "(Note: There are other important lessons that we can learn from this model, but they are beyond the scope of this class. For one, you may search Google for the concept of the \"two-portfolio separation theorem.\" Also note that we are excluding any \"risk-free\" short-term assets from our analysis here. Also note that Markowitz won the Nobel prize in economics in 1990 for this analysis.)\n",
    "\n",
    "Suppose that $\\mu$ is a column vector of the means of each asset and suppose that $\\Sigma$ is the associated variance-covariance matrix. Now, suppose that we create a column vector of weights $w$ that tells us the fraction of our wealth that we invest in each asset. Then, the formulas in matrix notation for the mean and variance of the resulting portfolio are\n",
    "$$\n",
    "\\mu_p = \\mu' w\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\sigma_p^2 = w' \\Sigma w\n",
    "$$\n",
    "respectively.\n",
    "\n",
    "In this folder, there should be a file called `dataAssets.csv`. Make sure that you have this file. Run the code below to load the data into numpy arrays.\n",
    "\n",
    "In the matrix of prices, each row corresponds to a day. The columns correspond, (in order,) to the S&P 500 index, USD index, crude oil index, HYG index, and U.S. 10-yr Treasury index. Here I have converted prices to returns for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_assets = pd.read_csv('./dataAssets.csv', parse_dates=['date'])\n",
    "prices = data_assets.iloc[:,1:].values\n",
    "dates = data_assets.iloc[:,0].values\n",
    "rets = (prices[1:,:]/prices[:-1,:] - 1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)\n",
    "data_assets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (1) Compute the means of the assets and the variance-covariance matrix. Save the means as the numpy array `mu`. Save the variance-covariance matrix as the numpy array `Sigma`.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (2) For practice, create a vector of portfolio weights that puts equal weight on each of the five assets. Compute the mean and the variance of this portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (3) Solve for the optimal portfolio that solves the following contrained minimization problem given a target expected portfolio return of $\\mu_p = 0.01$.\n",
    " \n",
    "\\begin{align*}\n",
    "\\min_{w} \\quad & w' \\Sigma w \\\\\n",
    "\\text{s.t.} \\quad & w' \\mu = \\mu_p \\\\\n",
    "& w' \\mathbb 1 = 1 \n",
    "\\end{align*}\n",
    "where $\\mathbb 1$ is a conforming vector of ones. For an initial guess for the optimizer, choose a portfolio of equal weights to each asset (a $5 \\times 1$ vector of the value $0.2$).\n",
    "\n",
    "Use `scipy.optimize.fmin_slsqp`. In order to incorporate two constraints, carefully read the documentation regarding the keyword argument `eqcons`.\n",
    "\n",
    "Save the optimal set of portfolio weights as `wstar`. Calculate the variance of this optimal portfolio. Verify that the sum of the weights is numerically close to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - (4) Use `numpy.linspace` to create a vector of `N` values equally spaced from -0.01 to 2. Call this vector `mean_grid`. For each value in this mean grid with `N=100`, solve the above maximization problem with the value of the mean grid as the target expected portfolio return $\\mu_p$. For each solution, record the value of the objective. That is, record the minimal portfolio return variance needed to acheive the desired expected portfolio return. Plot the two vectors that result on a plot with the x-axis labelled 'Portfolio Return Variance', the y-axis labelled 'Mean Portfolio Return', and the title of plot as 'Mean-Variance Efficient Frontier'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Survey Question\n",
    "\n",
    "Record below an estimate of how long it took to complete this assignment. Give the answer in hours (e.g., 2.5 hours)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
